{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size (8650, 1)\n",
      "row number:  8650\n",
      "feature number:  1\n",
      "\n",
      "names of features:  ['doc']\n",
      "-------------------\n",
      "full data loaded\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "# читаем датасет\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# load dataset from file csv\n",
    "# f = 'D:/koltsov_python_scripts/Tomotopy/preprocessing_data/20news_lem.csv'\n",
    "f = 'C:/koltcov_python_scripts/Word_embeding project/coherence/lenta_lem_2_utf8.csv'\n",
    "#f = 'D:/koltsov_python_scripts/Tomotopy/preprocessing_data/WoS11967_lem_1.csv'\n",
    "\n",
    "df=pd.read_csv(f,  sep=';', encoding='utf8')\n",
    "#df=pd.read_csv(f,  sep=';', encoding='cp1252' )\n",
    "#df=pd.read_csv(f,  sep=';', encoding='Latin-1')\n",
    "# df=pd.read_csv(f,  sep=';', encoding='ANSI')\n",
    "\n",
    "# this gives us the size of the array\n",
    "print('Dataset size', df.shape)\n",
    "\n",
    "# here we can get size of array as two variables\n",
    "num_rows, num_feature = df.shape\n",
    "\n",
    "print('row number: ', num_rows)\n",
    "print('feature number: ', num_feature)\n",
    "print()\n",
    "print('names of features: ', list(df))\n",
    "\n",
    "print('-------------------')\n",
    "print('full data loaded')\n",
    "print('-------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# download Tokenizer \n",
    "nltk.download(\"punkt\")\n",
    "# создание объекта nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "# here we delited list\n",
    "y_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time of execution (sec) 91.71959733963013\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "# для того что бы огранизовать лематизацию пр помощи pymorphy2 организуем цикл по текстам\n",
    "# there will be a list of original texts\n",
    "x_data = []\n",
    "# there will be a list of lematized texts\n",
    "y_data = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range (num_rows):\n",
    "    doc_stem =''\n",
    "    s1 = df['doc'][i]\n",
    "\n",
    "    # удаляем не нужные символы\n",
    "    s2 =s1.replace(',', '')\n",
    "    s3 =s2.replace('.', '')\n",
    "    s4 = re.sub('[!@#$1234567890#—ツ►๑۩۞۩•*”˜˜”*°°*`]', '', s3)\n",
    "    tokens = word_tokenize(s3)\n",
    "    \n",
    "    for j in range(0,len(tokens)):\n",
    "        tokens[j] = morph.parse(tokens[j])[0].normal_form\n",
    "        doc_stem = doc_stem + tokens[j] + ' '\n",
    "    \n",
    "    #print(doc_stem)\n",
    "    \n",
    "    #print('-----------------------------------------------------------------------------')\n",
    "    #x_data.append(df['doc'][i])\n",
    "    y_data.append(doc_stem)\n",
    "\n",
    "stop = time.time()    \n",
    "# results is set lematized documents\n",
    "print('time of execution (sec)', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of documents:  8650 ---- number of features:  11222\n"
     ]
    }
   ],
   "source": [
    "# The CountVectorizer module in sklearn allows you to convert a set of texts into a matrix of tokens in the text. \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Convert a collection of text documents to a matrix of token counts\n",
    "vec = CountVectorizer()\n",
    "\n",
    "x = vec.fit_transform(y_data)\n",
    "data = vec.fit_transform(y_data).toarray()\n",
    "\n",
    "num_docs, num_feature =x.shape\n",
    "print('number of documents: ', num_docs,'----', 'number of features: ', num_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11222\n",
      "11222\n"
     ]
    }
   ],
   "source": [
    "print(len(vec.vocabulary_))\n",
    "print(len(vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(11226 unique tokens: ['аляска', 'анонсировать', 'баллистический', 'безопасность', 'беспрецедентный']...)\n",
      "number of tokens:  11226\n",
      "number of docs:  8650\n",
      "number of docs:  8650\n",
      "time of execution (sec) 3.043997049331665\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "start = time.time()\n",
    "# Tokenize(split) the sentences into words\n",
    "texts = [[text for text in doc.split()] for doc in y_data]\n",
    "# Create dictionary\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "# create a corpus\n",
    "gensim_dictionary = corpora.Dictionary(texts)\n",
    "gensim_corpus = [gensim_dictionary.doc2bow(token, allow_update=True) for token in texts]\n",
    "\n",
    "# Get information about the dictionary and corpus\n",
    "print(dictionary)\n",
    "print('number of tokens: ', len(dictionary))\n",
    "print('number of docs: ', len(texts))\n",
    "print('number of docs: ', len(gensim_corpus))\n",
    "stop = time.time()    \n",
    "# results is set lematized documents\n",
    "print('time of execution (sec)', stop - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "итак, мы подготовили документы и словарь для расчета coherence\n",
    "теперь нужно считать матрицу рапределения слов и из нее вытажить \n",
    "списки топовых слов по каждой теме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size (7867, 20)\n",
      "row number:  7867\n",
      "feature number:  20\n",
      "\n",
      "names of features:  ['Unnamed: 0', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18']\n",
      "-------------------\n",
      "full data loaded\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "# читаем матрицу слов как датафрейм\n",
    "f = 'C:/koltcov_python_scripts/Word_embeding project/coherence/rus_vectors_embeddings_19_train_1_200_Phi.csv'\n",
    "phidf=pd.read_csv(f,  sep=';', encoding='ANSI')\n",
    "# this gives us the size of the array\n",
    "print('Dataset size', phidf.shape)\n",
    "\n",
    "# here we can get size of array as two variables\n",
    "num_rows, num_feature = phidf.shape\n",
    "\n",
    "print('row number: ', num_rows)\n",
    "print('feature number: ', num_feature)\n",
    "print()\n",
    "print('names of features: ', list(phidf))\n",
    "\n",
    "print('-------------------')\n",
    "print('full data loaded')\n",
    "print('-------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>корпорация</td>\n",
       "      <td>8.902018e-06</td>\n",
       "      <td>1.654974e-06</td>\n",
       "      <td>1.458763e-03</td>\n",
       "      <td>4.119167e-04</td>\n",
       "      <td>3.746196e-06</td>\n",
       "      <td>2.206045e-06</td>\n",
       "      <td>1.907293e-06</td>\n",
       "      <td>9.280930e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.617924e-03</td>\n",
       "      <td>4.180690e-05</td>\n",
       "      <td>4.492129e-06</td>\n",
       "      <td>5.368213e-06</td>\n",
       "      <td>2.675426e-06</td>\n",
       "      <td>6.017845e-06</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>4.505778e-07</td>\n",
       "      <td>2.250381e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>универмаг</td>\n",
       "      <td>8.202667e-07</td>\n",
       "      <td>9.632521e-07</td>\n",
       "      <td>2.827780e-06</td>\n",
       "      <td>7.055913e-07</td>\n",
       "      <td>3.106353e-07</td>\n",
       "      <td>1.475976e-06</td>\n",
       "      <td>4.086891e-07</td>\n",
       "      <td>1.044617e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>9.965071e-07</td>\n",
       "      <td>1.448219e-06</td>\n",
       "      <td>3.187734e-07</td>\n",
       "      <td>2.062774e-06</td>\n",
       "      <td>8.050685e-07</td>\n",
       "      <td>3.282399e-07</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>1.678579e-06</td>\n",
       "      <td>6.879072e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>louis</td>\n",
       "      <td>9.143426e-07</td>\n",
       "      <td>5.843416e-07</td>\n",
       "      <td>2.653134e-06</td>\n",
       "      <td>1.637984e-06</td>\n",
       "      <td>2.126544e-07</td>\n",
       "      <td>1.419391e-06</td>\n",
       "      <td>7.456376e-07</td>\n",
       "      <td>1.025717e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.337204e-06</td>\n",
       "      <td>6.334690e-07</td>\n",
       "      <td>2.250528e-07</td>\n",
       "      <td>1.749954e-06</td>\n",
       "      <td>1.556454e-06</td>\n",
       "      <td>2.241893e-07</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.138570e-06</td>\n",
       "      <td>1.096217e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>фетис</td>\n",
       "      <td>4.352915e-07</td>\n",
       "      <td>9.881717e-07</td>\n",
       "      <td>2.196915e-05</td>\n",
       "      <td>1.982393e-06</td>\n",
       "      <td>7.669111e-07</td>\n",
       "      <td>1.164320e-05</td>\n",
       "      <td>1.836156e-06</td>\n",
       "      <td>1.686463e-04</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.478178e-06</td>\n",
       "      <td>2.361681e-06</td>\n",
       "      <td>8.145795e-07</td>\n",
       "      <td>4.386285e-06</td>\n",
       "      <td>3.620375e-06</td>\n",
       "      <td>7.432017e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.606110e-06</td>\n",
       "      <td>1.536725e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>возбуждение</td>\n",
       "      <td>1.730360e-06</td>\n",
       "      <td>5.729775e-04</td>\n",
       "      <td>4.982857e-07</td>\n",
       "      <td>7.165572e-07</td>\n",
       "      <td>1.212593e-06</td>\n",
       "      <td>5.225035e-07</td>\n",
       "      <td>2.193131e-06</td>\n",
       "      <td>1.095204e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.208826e-06</td>\n",
       "      <td>8.873915e-06</td>\n",
       "      <td>1.776835e-06</td>\n",
       "      <td>7.891902e-05</td>\n",
       "      <td>2.358903e-06</td>\n",
       "      <td>9.682977e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>9.839202e-06</td>\n",
       "      <td>1.281997e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>джонатан</td>\n",
       "      <td>1.348272e-06</td>\n",
       "      <td>1.822061e-06</td>\n",
       "      <td>1.503479e-06</td>\n",
       "      <td>7.644163e-07</td>\n",
       "      <td>1.028842e-06</td>\n",
       "      <td>1.848728e-06</td>\n",
       "      <td>8.165979e-07</td>\n",
       "      <td>3.445128e-06</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>1.915792e-06</td>\n",
       "      <td>7.057784e-07</td>\n",
       "      <td>1.011118e-06</td>\n",
       "      <td>6.031982e-05</td>\n",
       "      <td>2.606348e-06</td>\n",
       "      <td>1.060634e-06</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>2.130533e-06</td>\n",
       "      <td>8.720277e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>моника</td>\n",
       "      <td>1.800773e-06</td>\n",
       "      <td>2.901000e-05</td>\n",
       "      <td>7.516395e-07</td>\n",
       "      <td>5.516647e-07</td>\n",
       "      <td>1.311752e-06</td>\n",
       "      <td>1.643767e-04</td>\n",
       "      <td>2.318481e-06</td>\n",
       "      <td>2.235558e-06</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>2.676147e-06</td>\n",
       "      <td>7.383351e-07</td>\n",
       "      <td>1.172423e-06</td>\n",
       "      <td>9.042326e-07</td>\n",
       "      <td>3.592328e-06</td>\n",
       "      <td>9.039379e-07</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>2.144181e-05</td>\n",
       "      <td>4.224069e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>кристофер</td>\n",
       "      <td>2.093107e-06</td>\n",
       "      <td>1.763958e-05</td>\n",
       "      <td>2.713066e-06</td>\n",
       "      <td>1.698303e-05</td>\n",
       "      <td>4.332009e-06</td>\n",
       "      <td>1.939515e-06</td>\n",
       "      <td>1.049077e-06</td>\n",
       "      <td>1.451365e-05</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>1.736215e-06</td>\n",
       "      <td>1.909535e-06</td>\n",
       "      <td>4.350151e-06</td>\n",
       "      <td>2.575525e-05</td>\n",
       "      <td>3.284546e-06</td>\n",
       "      <td>4.116194e-06</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>1.592024e-05</td>\n",
       "      <td>1.813317e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>занятость</td>\n",
       "      <td>2.592312e-06</td>\n",
       "      <td>2.468589e-06</td>\n",
       "      <td>2.285690e-06</td>\n",
       "      <td>1.580755e-04</td>\n",
       "      <td>5.496201e-06</td>\n",
       "      <td>4.589315e-06</td>\n",
       "      <td>3.333927e-06</td>\n",
       "      <td>1.439194e-06</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>8.224458e-07</td>\n",
       "      <td>6.927769e-06</td>\n",
       "      <td>6.352322e-06</td>\n",
       "      <td>1.785996e-06</td>\n",
       "      <td>3.631725e-06</td>\n",
       "      <td>4.600655e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>6.866523e-05</td>\n",
       "      <td>3.331691e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>осматривать</td>\n",
       "      <td>7.817801e-06</td>\n",
       "      <td>1.589077e-04</td>\n",
       "      <td>3.861429e-06</td>\n",
       "      <td>3.376359e-07</td>\n",
       "      <td>3.201790e-06</td>\n",
       "      <td>2.276997e-06</td>\n",
       "      <td>8.961468e-07</td>\n",
       "      <td>1.283730e-06</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>6.684770e-05</td>\n",
       "      <td>1.769789e-06</td>\n",
       "      <td>3.440636e-06</td>\n",
       "      <td>3.579619e-06</td>\n",
       "      <td>1.428577e-06</td>\n",
       "      <td>3.225548e-06</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.212048e-06</td>\n",
       "      <td>2.198661e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         words             0             1             2             3  \\\n",
       "0   корпорация  8.902018e-06  1.654974e-06  1.458763e-03  4.119167e-04   \n",
       "1    универмаг  8.202667e-07  9.632521e-07  2.827780e-06  7.055913e-07   \n",
       "2        louis  9.143426e-07  5.843416e-07  2.653134e-06  1.637984e-06   \n",
       "3        фетис  4.352915e-07  9.881717e-07  2.196915e-05  1.982393e-06   \n",
       "4  возбуждение  1.730360e-06  5.729775e-04  4.982857e-07  7.165572e-07   \n",
       "5     джонатан  1.348272e-06  1.822061e-06  1.503479e-06  7.644163e-07   \n",
       "6       моника  1.800773e-06  2.901000e-05  7.516395e-07  5.516647e-07   \n",
       "7    кристофер  2.093107e-06  1.763958e-05  2.713066e-06  1.698303e-05   \n",
       "8    занятость  2.592312e-06  2.468589e-06  2.285690e-06  1.580755e-04   \n",
       "9  осматривать  7.817801e-06  1.589077e-04  3.861429e-06  3.376359e-07   \n",
       "\n",
       "              4             5             6             7         8  \\\n",
       "0  3.746196e-06  2.206045e-06  1.907293e-06  9.280930e-07  0.000001   \n",
       "1  3.106353e-07  1.475976e-06  4.086891e-07  1.044617e-06  0.000004   \n",
       "2  2.126544e-07  1.419391e-06  7.456376e-07  1.025717e-06  0.000002   \n",
       "3  7.669111e-07  1.164320e-05  1.836156e-06  1.686463e-04  0.000004   \n",
       "4  1.212593e-06  5.225035e-07  2.193131e-06  1.095204e-06  0.000003   \n",
       "5  1.028842e-06  1.848728e-06  8.165979e-07  3.445128e-06  0.000030   \n",
       "6  1.311752e-06  1.643767e-04  2.318481e-06  2.235558e-06  0.000038   \n",
       "7  4.332009e-06  1.939515e-06  1.049077e-06  1.451365e-05  0.000038   \n",
       "8  5.496201e-06  4.589315e-06  3.333927e-06  1.439194e-06  0.000011   \n",
       "9  3.201790e-06  2.276997e-06  8.961468e-07  1.283730e-06  0.000203   \n",
       "\n",
       "              9            10            11            12            13  \\\n",
       "0  1.617924e-03  4.180690e-05  4.492129e-06  5.368213e-06  2.675426e-06   \n",
       "1  9.965071e-07  1.448219e-06  3.187734e-07  2.062774e-06  8.050685e-07   \n",
       "2  1.337204e-06  6.334690e-07  2.250528e-07  1.749954e-06  1.556454e-06   \n",
       "3  1.478178e-06  2.361681e-06  8.145795e-07  4.386285e-06  3.620375e-06   \n",
       "4  1.208826e-06  8.873915e-06  1.776835e-06  7.891902e-05  2.358903e-06   \n",
       "5  1.915792e-06  7.057784e-07  1.011118e-06  6.031982e-05  2.606348e-06   \n",
       "6  2.676147e-06  7.383351e-07  1.172423e-06  9.042326e-07  3.592328e-06   \n",
       "7  1.736215e-06  1.909535e-06  4.350151e-06  2.575525e-05  3.284546e-06   \n",
       "8  8.224458e-07  6.927769e-06  6.352322e-06  1.785996e-06  3.631725e-06   \n",
       "9  6.684770e-05  1.769789e-06  3.440636e-06  3.579619e-06  1.428577e-06   \n",
       "\n",
       "             14        15        16            17            18  \n",
       "0  6.017845e-06  0.000133  0.000006  4.505778e-07  2.250381e-06  \n",
       "1  3.282399e-07  0.000312  0.000091  1.678579e-06  6.879072e-07  \n",
       "2  2.241893e-07  0.000208  0.000003  1.138570e-06  1.096217e-06  \n",
       "3  7.432017e-07  0.000004  0.000002  2.606110e-06  1.536725e-06  \n",
       "4  9.682977e-07  0.000001  0.000008  9.839202e-06  1.281997e-03  \n",
       "5  1.060634e-06  0.000296  0.000007  2.130533e-06  8.720277e-07  \n",
       "6  9.039379e-07  0.000157  0.000005  2.144181e-05  4.224069e-06  \n",
       "7  4.116194e-06  0.000154  0.000074  1.592024e-05  1.813317e-06  \n",
       "8  4.600655e-06  0.000002  0.000005  6.866523e-05  3.331691e-04  \n",
       "9  3.225548e-06  0.000005  0.000004  3.212048e-06  2.198661e-06  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phidf=phidf.rename(columns={'Unnamed: 0': 'words'})\n",
    "phidf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "теперерь нужно отсортиоовать по вероятности в каждой колонке, \n",
    "что бы получить наиболее вероятностеые слова,\n",
    "то есть содержимое каждой темы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['организация', 'террористический', 'россия', 'запрещать', 'группировка', 'сирия', 'государство', 'исламский', 'территория', 'боевик']\n"
     ]
    }
   ],
   "source": [
    "sorted_df = phidf.sort_values(by='0', ascending = False)\n",
    "print(sorted_df['words'].head(10).to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# организуем сортировку по каждой колонке, \n",
    "# и будем сохранять слова в колонке 'words'\n",
    "mytopics = []\n",
    "# создаем список мен столбцов\n",
    "topics_name =list(phidf)\n",
    "topics_name.remove('words')\n",
    "# цикл по именам столбцов\n",
    "for i in topics_name:\n",
    "    # сортируем по текущему столбцу\n",
    "    sorted_df = phidf.sort_values(by=i, ascending = False)\n",
    "    mytopics.append(sorted_df['words'].head(5).to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['организация', 'террористический', 'россия', 'запрещать', 'группировка'], ['полиция', 'происходить', 'мужчина', 'летний', 'сотрудник'], ['компания', 'российский', 'процент', 'тысяча', 'миллиард'], ['доллар', 'рубль', 'россия', 'процент', 'банк'], ['проводить', 'тысяча', 'работа', 'страна', 'место'], ['россия', 'президент', 'российский', 'украина', 'владимир'], ['россия', 'страна', 'отношение', 'министр', 'санкция'], ['россия', 'чемпионат', 'команда', 'российский', 'матч'], ['ребёнок', 'город', 'летний', 'штат', 'женщина'], ['самолёт', 'ракета', 'военный', 'борт', 'километр'], ['россия', 'закон', 'правительство', 'президент', 'глава'], ['работа', 'проводить', 'тысяча', 'страна', 'место'], ['учёный', 'исследование', 'журнал', 'результат', 'обнаруживать'], ['президент', 'партия', 'выбор', 'кандидат', 'пост'], ['проводить', 'работа', 'тысяча', 'страна', 'место'], ['компания', 'фильм', 'основывать', 'выпускать', 'представлять'], ['сеть', 'пользователь', 'видео', 'соцсеть', 'страница'], ['телеканал', 'журналист', 'интервью', 'отказываться', 'заявление'], ['уголовный', 'рубль', 'россия', 'признавать', 'статья']]\n"
     ]
    }
   ],
   "source": [
    "print(mytopics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.6245082112055202\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import common_corpus, common_dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "cm = CoherenceModel(topics=mytopics, corpus=gensim_corpus, dictionary=gensim_dictionary, coherence='u_mass')\n",
    "coherence = cm.get_coherence()  # get coherence value\n",
    "print(coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
